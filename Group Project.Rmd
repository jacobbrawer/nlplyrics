---
title: "Group Project"
author: "Will Abele, Jacob Brawer, Owen Rosebeck"
date: 'Wednesday, December 18'
output:
  html_document: default
  pdf_document: default
---

https://prezi.com/view/zYGal9DWEFulQ9FjeTOM/

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
songs2013 <- read.csv("songs2013.csv")
songs2013[songs2013 == "null"] <- NA
songs2013 <- na.omit(songs2013)

```

```{r}
library(tm)
library(tidyverse)
songs <- read.csv("prepped_data.csv")
songs <- rbind(songs, songs2013)

stopWords <- c("chorus ", "verse ", "intro ", "1 ", "bridge ", "2 ", "Chorus ", "Intro ", "Verse ", "Bridge ")


songs <- songs %>% 
  select(Album, Artist, Lyrics, Rank, Song.Title, Year, Verbs, Nouns, Adverbs, Word.Counts, Corpus) %>%
  mutate(Lyrics = as.character(Lyrics)) %>% 
  mutate(Verbs = as.character(Verbs)) %>% 
  mutate(Nouns = as.character(Nouns)) %>% 
  mutate(Adverbs = as.character(Adverbs)) %>% 
  mutate(Nouns = removeWords(Nouns, stopWords)) %>%
  mutate(Decade = ifelse(Year < 1980, 1970, ifelse(Year < 1990, 1980, ifelse(Year < 2000, 1990, ifelse(Year < 2010, 2000, 2010))))) %>% 
  mutate(Corpus = removeWords(tolower(as.character(Corpus)), stopWords)) 


```

```{r}
library(tidyverse)
library(stringr)
library(wordcloud2)
library(tidytext)
library(Rcpp)

songtoken <- songs %>%
  select(Nouns) %>%
  unnest_tokens(output = word, input = Nouns)

song_tidy <- songtoken %>% 
  group_by(word) %>%
  count() %>% 
  arrange(desc(n))

wordcloud2(data = song_tidy[1:100,], size = 1, color = "random-light")
```


```{r}
songs70 <- songs %>%
  filter(Decade == 1970)

songs80 <- songs %>%
  filter(Decade == 1980)

songs90 <- songs %>%
  filter(Decade == 1990)

songs00 <- songs %>%
  filter(Decade == 2000)

songs10 <- songs %>%
  filter(Decade == 2010)

yearlist <- c(1970:2019)

top10 <- c()
for(i in c(1:10)){
  top10 <- c(top10, song_tidy[i, 1])
}

masterwordlist <- data.frame()


for (i in yearlist){
  
yearsongtoken <- songs %>%
  filter(Year == i) %>%
  select(Nouns) %>%
  unnest_tokens(output = word, input = Nouns)

year_song_tidy <- yearsongtoken %>% 
  filter(word == top10[1] | word == top10[2] | word == top10[3] |word == top10[4] |word == top10[5] |word == top10[6] |word == top10[7] |word == top10[8] |word == top10[9] |word == top10[10]) %>%
  group_by(word) %>%
  count() %>% 
  arrange(desc(n)) %>%
  mutate(Year = i)

if (length(masterwordlist) == 0 ){
  masterwordlist <- year_song_tidy 
}else{
  
masterwordlist <- merge(year_song_tidy, masterwordlist, all = TRUE)
  }
}

```


```{r}

songtoken70 <- songs70 %>%
  select(Song.Title, Nouns) %>%
  unnest_tokens(output = word, input = Nouns)

song_tidy70 <- songtoken70 %>% 
  group_by(word) %>%
  count() %>% 
  arrange(desc(n))

wordcloud2(data = song_tidy70[1:100,], size = 1, color = "random-light")


songtoken80 <- songs80 %>%
  select(Song.Title, Nouns) %>%
  unnest_tokens(output = word, input = Nouns)

song_tidy80 <- songtoken80 %>% 
  group_by(word) %>%
  count() %>% 
  arrange(desc(n))

wordcloud2(data = song_tidy80[1:100,], size = 1, color = "random-light")


songtoken90 <- songs90 %>%
  select(Song.Title, Nouns) %>%
  unnest_tokens(output = word, input = Nouns)

song_tidy90 <- songtoken90 %>% 
  group_by(word) %>%
  count() %>% 
  arrange(desc(n))

wordcloud2(data = song_tidy90[1:100,], size = 1, color = "random-light")



songtoken00 <- songs00 %>%
  select(Song.Title, Nouns) %>%
  unnest_tokens(output = word, input = Nouns)

song_tidy00 <- songtoken00 %>% 
  group_by(word) %>%
  count() %>% 
  arrange(desc(n))

wordcloud2(data = song_tidy00[1:100,], size = 1, color = "random-light")



songtoken10 <- songs10 %>%
  select(Song.Title, Nouns) %>%
  unnest_tokens(output = word, input = Nouns)

song_tidy10 <- songtoken10 %>% 
  group_by(word) %>%
  count() %>% 
  arrange(desc(n))

wordcloud2(data = song_tidy10[1:100,], size = 1, color = "random-light")


```

```{r}
ggplot(masterwordlist, aes(x = Year, y = n, color = word)) + geom_line()

```

```{r}
library(gplots)
library(dplyr)
library(tidyverse)

arrangedmasterwordlist <- masterwordlist %>%
  group_by(word) %>%
  arrange((Year))

widemasterwordlist <- data.frame(pivot_wider(arrangedmasterwordlist, id_cols = word, names_from = Year, values_from = n))
row.names(widemasterwordlist) <- widemasterwordlist$word
masterwordmatrix <- data.matrix(widemasterwordlist[,-1])

wordheatmap <- heatmap(masterwordmatrix, Rowv = NA, Colv = NA, col = heat.colors(256), scale = "column", margins = c(5, 10))
```

```{r}
library(dplyr) #Data manipulation (also included in the tidyverse package)
library(tidyr) #Spread, separate, unite, text mining (also included in the tidyverse package)
library(widyr) #Use for pairwise correlation

#Visualizations!
library(ggplot2) #Visualizations (also included in the tidyverse package)
library(ggrepel) #`geom_label_repel`
library(gridExtra) #`grid.arrange()` for multi-graphs
library(knitr) #Create nicely formatted output tables
library(kableExtra) #Create nicely formatted output tables
library(formattable) #For the color_tile function
library(circlize) #Visualizations - chord diagram
# library(remotes)
# install_github("EmilHvitfeldt/textdata")
# install_github("juliasilge/tidytext")
library(tidytext) #Text mining
library(textdata)

afinn <- get_sentiments("afinn")
bing <- get_sentiments("bing")
nrc <- get_sentiments("nrc")
```

```{r}
library(textdata)
library(tidytext)
library(radarchart)

nrc <- get_sentiments("nrc")
afinn <- get_sentiments("afinn")
bing <- get_sentiments("bing")


song70_nrc <- song_tidy70 %>% 
  inner_join(nrc) %>% 
  filter(!sentiment %in% c("negative", "positive")) %>% 
  group_by(sentiment) %>%
  summarise(Sent_Count = sum(n)) %>% 
  mutate(Sentiment = (Sent_Count/sum(Sent_Count))*100)

radar_chart_70s <- song70_nrc %>%
  select(-Sent_Count) %>% 
  chartJSRadar(showToolTipLabel = TRUE, main = "1970s Sentiment")

radar_chart_70s

song80_nrc <- song_tidy80 %>% 
  inner_join(nrc) %>% 
  filter(!sentiment %in% c("negative", "positive")) %>% 
  group_by(sentiment) %>%
  summarise(Sent_Count = sum(n)) %>% 
  mutate(Sentiment = (Sent_Count/sum(Sent_Count))*100)

radar_chart_80s <- song80_nrc %>%
  select(-Sent_Count) %>% 
  chartJSRadar(showToolTipLabel = TRUE, main = "1980s Sentiment")

radar_chart_80s

song90_nrc <- song_tidy90 %>% 
  inner_join(nrc) %>% 
  filter(!sentiment %in% c("negative", "positive")) %>% 
  group_by(sentiment) %>%
  summarise(Sent_Count = sum(n)) %>% 
  mutate(Sentiment = (Sent_Count/sum(Sent_Count))*100)

radar_chart_90s <- song90_nrc %>%
  select(-Sent_Count) %>% 
  chartJSRadar(showToolTipLabel = TRUE, main = "1990s Sentiment")

radar_chart_90s

song00_nrc <- song_tidy00 %>% 
  inner_join(nrc) %>% 
  filter(!sentiment %in% c("negative", "positive")) %>% 
  group_by(sentiment) %>%
  summarise(Sent_Count = sum(n)) %>% 
  mutate(Sentiment = (Sent_Count/sum(Sent_Count))*100)

radar_chart_00s <- song00_nrc %>%
  select(-Sent_Count) %>% 
  chartJSRadar(showToolTipLabel = TRUE, main = "2000s Sentiment")

radar_chart_00s

song10_nrc <- song_tidy10 %>% 
  inner_join(nrc) %>% 
  filter(!sentiment %in% c("negative", "positive")) %>% 
  group_by(sentiment) %>%
  summarise(Sent_Count = sum(n)) %>% 
  mutate(Sentiment = (Sent_Count/sum(Sent_Count))*100)

radar_chart_10s <- song10_nrc %>%
  select(-Sent_Count) %>% 
  chartJSRadar(showToolTipLabel = TRUE, main = "2010s Sentiment")

radar_chart_10s
```


```{r}
my_colors <- c("#E69F00", "#56B4E9", "#009E73", "#CC79A7", "#D55E00")

theme_lyrics <- function() 
{
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_blank(), 
        axis.ticks = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none")
}

lex_diversity_per_year <- songs %>%
  unnest_tokens(word, Lyrics) %>%
  group_by(Song.Title,Year) %>%
  summarise(lex_diversity = n_distinct(word)) %>%
  arrange(desc(lex_diversity)) 

diversity_plot <- lex_diversity_per_year %>%
  ggplot(aes(Year, lex_diversity)) +
    geom_point(color = my_colors[3],
               alpha = .3, 
               size = 1, position = "jitter") + 
    stat_smooth(color = "black", se = FALSE, method = "lm") +
    geom_smooth(aes(x = Year, y = lex_diversity), se = FALSE,
                color = "blue", lwd = 2) +
    ggtitle("Lexical Diversity") +
    xlab("Year") + 
    ylab("") +
    scale_color_manual(values = my_colors) +
    theme_classic() + 
    theme_lyrics()

diversity_plot
```


```{r}
lex_density_per_year <- songs %>%
  unnest_tokens(word, Lyrics) %>%
  group_by(Song.Title,Year) %>%
  summarise(lex_density = n_distinct(word)/n()) %>%
  arrange(desc(lex_density))

density_plot <- lex_density_per_year %>%
  ggplot(aes(Year, lex_density)) + 
    geom_point(color = my_colors[4],
               alpha = .4, 
               size = 2, 
               position = "jitter") + 
    stat_smooth(color = "black", 
                se = FALSE, 
                method = "lm") +
    geom_smooth(aes(x = Year, y = lex_density), 
                  se = FALSE,
                  color = "blue", 
                  lwd = 2) +
      ggtitle("Lexical Density") + 
      xlab("Year") + 
      ylab("") +
      scale_color_manual(values = my_colors) +
      theme_classic() + 
      theme_lyrics()

density_plot

```


```{r}
library(tidytext) 
library(RColorBrewer)

tfidf_words_decade <- songs %>%
  unnest_tokens(word, Lyrics) %>%
  distinct() %>%
  filter(nchar(word) > 3) %>%
  count(Decade, word, sort = TRUE) %>%
  bind_tf_idf(word, Decade, n) %>%
  arrange(desc(tf_idf))

top_tfidf_words_decade <- tfidf_words_decade %>% 
  group_by(Decade) %>% 
  slice(seq_len(8)) %>%
  ungroup() %>%
  arrange(Decade, tf_idf) %>%
  mutate(row = row_number())

top_tfidf_words_decade %>%
  ggplot(aes(x = row, tf_idf, fill = Decade)) +
    geom_col(show.legend = NULL) +
    labs(x = NULL, y = "TF-IDF") + 
    ggtitle("Important Words using TF-IDF by Decade") +
    theme_lyrics() +  
    facet_wrap(~Decade, 
               ncol = 3, nrow = 2, 
               scales = "free") +
    scale_x_continuous(  # this handles replacement of row 
        breaks = top_tfidf_words_decade$row, # notice need to reuse dataframe
        labels = top_tfidf_words_decade$word) +
    coord_flip()
```

```{r}
timeless_artists <- songs %>%
  select(Artist, Year) %>%
  group_by(Year) %>%
  distinct(Artist) %>%
  ungroup() %>%
  group_by(Artist) %>%
  count() %>%
  arrange(desc(n)) %>%
  head(25)

topartist_token <- songs %>%
  mutate(timeless = ifelse(Artist == "Madonna" | Artist == "Elton John" | Artist == "Mariah Carey" | Artist == "Taylor Swift" | Artist == "Chicago" | Artist == "Stevie Wonder" | Artist == "Kelly Clarkson" | Artist == "Michael Jackson" | Artist == "Rihanna" | Artist == "Aerosmith" | Artist == "Daryl Hall and John Oates" | Artist ==	"Drake"	| Artist == "Janet Jackson" | Artist ==	"Beyonce"	| Artist == "Bon Jovi" | Artist == "Celine Dion" | Artist == "Cher" | Artist == "Commodores" | Artist == "Eminem" | Artist == "Eric Clapton" | Artist == "Justin Timberlake" | Artist == "Maroon 5" | Artist == "Olivia Newton-John" | Artist =="Rod Stewart" | Artist =="Usher", "Top Artist", "Total"))

tfidf_words_timeless <- topartist_token %>%
  unnest_tokens(word, Lyrics) %>%
  distinct() %>%
  filter(nchar(word) > 3) %>%
  count(timeless, word, sort = TRUE) %>%
  bind_tf_idf(word, timeless, n) %>%
  arrange(desc(tf_idf))

top_tfidf_words_timeless <- tfidf_words_timeless %>% 
  group_by(timeless) %>% 
  slice(seq_len(10)) %>%
  ungroup() %>%
  arrange(timeless, tf_idf) %>%
  mutate(row = row_number())

top_tfidf_words_timeless %>%
  ggplot(aes(x = row, tf_idf, fill = timeless)) +
    geom_col(show.legend = NULL) +
    labs(x = NULL, y = "TF-IDF") + 
    ggtitle("Important Words using TF-IDF by Decade") +
    theme_lyrics() +  
    facet_wrap(~timeless, 
               ncol = 3, nrow = 2, 
               scales = "free") +
    scale_x_continuous(  # this handles replacement of row 
        breaks = top_tfidf_words_timeless$row, # notice need to reuse dataframe
        labels = top_tfidf_words_timeless$word) +
    coord_flip()

```

```{r}
library(reshape2)
library(wordcloud)


song_compcloud70 <- songtoken70 %>% 
  inner_join(bing) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)

```

```{r}
song_tidy80 <- songtoken80 %>% 
  inner_join(bing) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)
```

```{r}
song_tidy90 <- songtoken90 %>% 
  inner_join(bing) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)
```

```{r}
song_tidy00 <- songtoken00 %>% 
  inner_join(bing) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)
```

```{r}
song_tidy10 <- songtoken10 %>% 
  inner_join(bing) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)

```

```{r}
song_bigrams <- songs %>%
  unnest_tokens(bigram, Corpus, token = "ngrams", n = 2)

bigrams_separated <- song_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")

bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) %>%
  filter(nchar(word1) > 2) %>%
  filter(nchar(word2) > 2)
 

bigram_decade <- bigrams_filtered %>%
  filter(word1 != word2) %>%
  unite(bigram, word1, word2, sep = " ") %>%
  count(bigram, Decade, sort = TRUE) %>%
  group_by(Decade) %>%
  slice(seq_len(10)) %>%
  ungroup() %>%
  arrange(Decade, n) %>%
  mutate(row = row_number())

```

```{r}
ggplot(bigram_decade, aes(x= row, y = n, fill = Decade)) + geom_col(show.legend = FALSE) + facet_wrap(~Decade, scales = "free_y") +
  xlab(NULL) + ylab(NULL) + scale_x_continuous(breaks = bigram_decade$row, labels = bigram_decade$bigram) + theme(panel.grid.major.x = element_blank()) + ggtitle("Bigrams Per Decade") + coord_flip()

```

```{r}
library(ggraph)

bigram_decade %>% select(bigram, n) %>%
  separate(bigram, c("word1", "word2")) %>%
  ggraph(layout = "fr") +
  geom_edge_link() +
  geom_node_point() +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1)
```

```{r}

song_noun <- songs %>% 
  dplyr::select(Song.Title, Nouns, Year) %>% 
  unnest_tokens(output = word, input = Nouns) %>% 
  mutate(Upos = "NOUN") %>% 
  mutate(Year = Year)

song_verb <- songs %>% 
  dplyr::select(Song.Title, Verbs, Year) %>% 
  unnest_tokens(output = word, input = Verbs)%>% 
  mutate(Upos = "VERB") %>% 
  mutate(Year = Year)

song_adverb <- songs %>% 
  dplyr::select(Song.Title, Adverbs, Year) %>% 
  unnest_tokens(output = word, input = Adverbs)%>% 
  mutate(Upos = "ADV") %>% 
  mutate(Year = Year)

song_upos <- rbind(rbind(song_noun,song_verb), song_adverb)
```


```{r}

t1 <- c("woah", "kiss", "life", "thing", "world", "song", "people") 

t2 <- c("tonight", "dance", "party", "hand", "thing")

t3 <- c("friend", "head", "woman", "lover", "lady", "ladies")

t4 <- c("shit", "bitch", "bottom", "water", "pussi", "pussy")

t5 <- c("money", "bodies", "type", "bitch", "cash", "body")

t6 <- c("name", "chance", "town", "rain", "tear")

t7 <- c("gang", "taste", "girlfriend", "wrist", "chain") 

t8 <- c("thunder", "star", "murder", "ghost", "wish")

topic_modeling <- function(topic, color, title){

  topic_plot <-  song_upos %>%
  filter(word %in% topic) %>%
  group_by(Year) %>%
  mutate(topic_count = n()) %>%
  select(Year, topic_count) %>%
  distinct() %>%
  ggplot(aes(Year, topic_count)) + geom_smooth(se = FALSE, col = color) + ggtitle(title)
  
  topic_plot
  
}

colors <- c("#89C5DA", "#DA5724", "#74D944", "#CE50CA", "#3F4921", "#C0717C", "#CBD588", "#5F7FC7", 
"#673770", "#D3D93E", "#38333E", "#508578", "#D7C1B1", "#689030", "#AD6F3B", "#CD9BCD", 
"#D14285", "#6DDE88", "#652926", "#7FDCC0", "#C84248", "#8569D5", "#5E738F", "#D1A33D", 
"#8A7C64", "#599861")

topic_modeling(t1, sample(colors, 1), "Passion/Longing")
topic_modeling(t2, sample(colors, 1), "Party/Dance/Movement")
topic_modeling(t3, sample(colors, 1), "Intimacy/Women")
topic_modeling(t4, sample(colors, 1), "Sex/Objectification")
topic_modeling(t5, sample(colors, 1), "Measurements of Clout")
topic_modeling(t6, sample(colors, 1), "Impulsivity/Sadness")
topic_modeling(t7, sample(colors, 1), "Commitment/Tether")
topic_modeling(t8, sample(colors, 1), "Faith/Violence")
```

