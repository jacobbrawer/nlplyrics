---
title: "Group Project"
author: "Will Abele, Jacob Brawer, Owen Rosebeck"
date: 'Wednesday, December 18'
output:
  html_document: default
  pdf_document: default
---

https://prezi.com/view/zYGal9DWEFulQ9FjeTOM/

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
songs2013 <- read.csv("songs2013.csv")
songs2013[songs2013 == "null"] <- NA
songs2013 <- na.omit(songs2013)

```

```{r}
library(tm)
library(tidyverse)
songs <- read.csv("prepped_data.csv")
songs <- rbind(songs, songs2013)

stopWords <- c("chorus ", "verse ", "intro ", "1 ", "bridge ", "2 ", "Chorus ", "Intro ", "Verse ", "Bridge ")


songs <- songs %>% 
  select(Album, Artist, Lyrics, Rank, Song.Title, Year, Verbs, Nouns, Adverbs, Word.Counts, Corpus) %>%
  mutate(Lyrics = as.character(Lyrics)) %>% 
  mutate(Verbs = as.character(Verbs)) %>% 
  mutate(Nouns = as.character(Nouns)) %>% 
  mutate(Adverbs = as.character(Adverbs)) %>% 
  mutate(Nouns = removeWords(Nouns, stopWords)) %>%
  mutate(Decade = ifelse(Year < 1980, 1970, ifelse(Year < 1990, 1980, ifelse(Year < 2000, 1990, ifelse(Year < 2010, 2000, 2010))))) %>% 
  mutate(Corpus = removeWords(tolower(as.character(Corpus)), stopWords)) 


```


```{r}
write.csv(songs, file = "final_songs.csv")
```


```{r}
library(tidyverse)
library(stringr)
library(wordcloud2)
library(tidytext)
library(Rcpp)

songtoken <- songs %>%
  select(Nouns) %>%
  unnest_tokens(output = word, input = Nouns)

song_tidy <- songtoken %>% 
  group_by(word) %>%
  count() %>% 
  arrange(desc(n))

wordcloud2(data = song_tidy[1:100,], size = 1, color = "RED")
```


```{r}
songs70 <- songs %>%
  filter(Decade == 1970)

songs80 <- songs %>%
  filter(Decade == 1980)

songs90 <- songs %>%
  filter(Decade == 1990)

songs00 <- songs %>%
  filter(Decade == 2000)

songs10 <- songs %>%
  filter(Decade == 2010)

yearlist <- c(1970:2019)

top10 <- c()
for(i in c(1:10)){
  top10 <- c(top10, song_tidy[i, 1])
}

masterwordlist <- data.frame()


for (i in yearlist){
  
yearsongtoken <- songs %>%
  filter(Year == i) %>%
  select(Nouns) %>%
  unnest_tokens(output = word, input = Nouns)

year_song_tidy <- yearsongtoken %>% 
  filter(word == top10[1] | word == top10[2] | word == top10[3] |word == top10[4] |word == top10[5] |word == top10[6] |word == top10[7] |word == top10[8] |word == top10[9] |word == top10[10]) %>%
  group_by(word) %>%
  count() %>% 
  arrange(desc(n)) %>%
  mutate(Year = i)

if (length(masterwordlist) == 0 ){
  masterwordlist <- year_song_tidy 
}else{
  
masterwordlist <- merge(year_song_tidy, masterwordlist, all = TRUE)
  }
}

```


```{r}

songtoken70 <- songs70 %>%
  select(Song.Title, Nouns) %>%
  unnest_tokens(output = word, input = Nouns)

song_tidy70 <- songtoken70 %>% 
  group_by(word) %>%
  count() %>% 
  arrange(desc(n))

wordcloud2(data = song_tidy70[1:100,], size = 1, color = "random-light")


songtoken80 <- songs80 %>%
  select(Song.Title, Nouns) %>%
  unnest_tokens(output = word, input = Nouns)

song_tidy80 <- songtoken80 %>% 
  group_by(word) %>%
  count() %>% 
  arrange(desc(n))

wordcloud2(data = song_tidy80[1:100,], size = 1, color = "random-light")


songtoken90 <- songs90 %>%
  select(Song.Title, Nouns) %>%
  unnest_tokens(output = word, input = Nouns)

song_tidy90 <- songtoken90 %>% 
  group_by(word) %>%
  count() %>% 
  arrange(desc(n))

wordcloud2(data = song_tidy90[1:100,], size = 1, color = "random-light")



songtoken00 <- songs00 %>%
  select(Song.Title, Nouns) %>%
  unnest_tokens(output = word, input = Nouns)

song_tidy00 <- songtoken00 %>% 
  group_by(word) %>%
  count() %>% 
  arrange(desc(n))

wordcloud2(data = song_tidy00[1:100,], size = 1, color = "random-light")



songtoken10 <- songs10 %>%
  select(Song.Title, Nouns) %>%
  unnest_tokens(output = word, input = Nouns)

song_tidy10 <- songtoken10 %>% 
  group_by(word) %>%
  count() %>% 
  arrange(desc(n))

wordcloud2(data = song_tidy10[1:100,], size = 1, color = "random-light")


```


```{r}
# top10 <- c()
# for(i in c(1:10)){
#   top10 <- c(top10, song_tidy[i, 1])
# }
# 
# songs70pop <- song_tidy70 %>%
#   filter(word == top10[1] | word == top10[2] | word == top10[3] |word == top10[4] |word == top10[5] |word == top10[6] |word == top10[7] |word == top10[8] |word == top10[9] |word == top10[10]) %>%
#   mutate(Decade = 1970)
# 
# songs80pop <- song_tidy80 %>%
#   filter(word == top10[1] | word == top10[2] | word == top10[3] |word == top10[4] |word == top10[5] |word == top10[6] |word == top10[7] |word == top10[8] |word == top10[9] |word == top10[10]) %>%
#   mutate(Decade = 1980)
# 
# songs90pop <- song_tidy90 %>%
#   filter(word == top10[1] | word == top10[2] | word == top10[3] |word == top10[4] |word == top10[5] |word == top10[6] |word == top10[7] |word == top10[8] |word == top10[9] |word == top10[10]) %>%
#   mutate(Decade = 1990)
# 
# songs00pop <- song_tidy00 %>%
#   filter(word == top10[1] | word == top10[2] | word == top10[3] |word == top10[4] |word == top10[5] |word == top10[6] |word == top10[7] |word == top10[8] |word == top10[9] |word == top10[10]) %>%
#   mutate(Decade = 2000)
# 
# songs10pop <- song_tidy10 %>%
#   filter(word == top10[1] | word == top10[2] | word == top10[3] |word == top10[4] |word == top10[5] |word == top10[6] |word == top10[7] |word == top10[8] |word == top10[9] |word == top10[10]) %>%
#   mutate(Decade = 2010)
```



```{r}
ggplot(masterwordlist, aes(x = Year, y = n, color = word)) + geom_line()

```
```{r}
library(gplots)
library(dplyr)
library(tidyverse)

arrangedmasterwordlist <- masterwordlist %>%
  group_by(word) %>%
  arrange((Year))

widemasterwordlist <- data.frame(pivot_wider(arrangedmasterwordlist, id_cols = word, names_from = Year, values_from = n))
row.names(widemasterwordlist) <- widemasterwordlist$word
masterwordmatrix <- data.matrix(widemasterwordlist[,-1])

wordheatmap <- heatmap(masterwordmatrix, Rowv = NA, Colv = NA, col = heat.colors(256), scale = "column", margins = c(5, 10))
```
```{r}
library(dplyr) #Data manipulation (also included in the tidyverse package)
library(tidyr) #Spread, separate, unite, text mining (also included in the tidyverse package)
library(widyr) #Use for pairwise correlation

#Visualizations!
library(ggplot2) #Visualizations (also included in the tidyverse package)
library(ggrepel) #`geom_label_repel`
library(gridExtra) #`grid.arrange()` for multi-graphs
library(knitr) #Create nicely formatted output tables
library(kableExtra) #Create nicely formatted output tables
library(formattable) #For the color_tile function
library(circlize) #Visualizations - chord diagram
# library(remotes)
# install_github("EmilHvitfeldt/textdata")
# install_github("juliasilge/tidytext")
library(tidytext) #Text mining
library(textdata)

# tidytext::sentiment
# 
# 
afinn <- get_sentiments("afinn")
bing <- get_sentiments("bing")
nrc <- get_sentiments("nrc")
# 
# 
# view(sentiments)
# 
# new_sentiments <- sentiments %>% #From the tidytext package
#   filter(lexicon != "loughran") %>% #Remove the finance lexicon
#   mutate( sentiment = ifelse(lexicon == "AFINN" & score >= 0, "positive",
#                               ifelse(lexicon == "AFINN" & score < 0,
#                                      "negative", sentiment))) %>%
#   group_by(lexicon) %>%
#   mutate(words_in_lexicon = n_distinct(word)) %>%
#   ungroup()
# 
# new_sentiments %>%
#   group_by(lexicon, sentiment, words_in_lexicon) %>%
#   summarise(distinct_words = n_distinct(word)) %>%
#   ungroup() %>%
#   spread(sentiment, distinct_words) %>%
#   mutate(lexicon = color_tile("lightblue", "lightblue")(lexicon),
#          words_in_lexicon = color_bar("lightpink")(words_in_lexicon)) %>%
#   my_kable_styling(caption = "Word Counts Per Lexicon")



```

```{r}
library(textdata)
library(tidytext)
library(radarchart)

nrc <- get_sentiments("nrc")
afinn <- get_sentiments("afinn")
bing <- get_sentiments("bing")


song70_nrc <- song_tidy70 %>% 
  inner_join(nrc) %>% 
  filter(!sentiment %in% c("negative", "positive")) %>% 
  group_by(sentiment) %>%
  summarise(Sent_Count = sum(n)) %>% 
  mutate(Sentiment = (Sent_Count/sum(Sent_Count))*100)

radar_chart_70s <- song70_nrc %>%
  select(-Sent_Count) %>% 
  chartJSRadar(showToolTipLabel = TRUE, main = "1970s Sentiment")

radar_chart_70s

song80_nrc <- song_tidy80 %>% 
  inner_join(nrc) %>% 
  filter(!sentiment %in% c("negative", "positive")) %>% 
  group_by(sentiment) %>%
  summarise(Sent_Count = sum(n)) %>% 
  mutate(Sentiment = (Sent_Count/sum(Sent_Count))*100)

radar_chart_80s <- song80_nrc %>%
  select(-Sent_Count) %>% 
  chartJSRadar(showToolTipLabel = TRUE, main = "1980s Sentiment")

radar_chart_80s

song90_nrc <- song_tidy90 %>% 
  inner_join(nrc) %>% 
  filter(!sentiment %in% c("negative", "positive")) %>% 
  group_by(sentiment) %>%
  summarise(Sent_Count = sum(n)) %>% 
  mutate(Sentiment = (Sent_Count/sum(Sent_Count))*100)

radar_chart_90s <- song90_nrc %>%
  select(-Sent_Count) %>% 
  chartJSRadar(showToolTipLabel = TRUE, main = "1990s Sentiment")

radar_chart_90s

song00_nrc <- song_tidy00 %>% 
  inner_join(nrc) %>% 
  filter(!sentiment %in% c("negative", "positive")) %>% 
  group_by(sentiment) %>%
  summarise(Sent_Count = sum(n)) %>% 
  mutate(Sentiment = (Sent_Count/sum(Sent_Count))*100)

radar_chart_00s <- song00_nrc %>%
  select(-Sent_Count) %>% 
  chartJSRadar(showToolTipLabel = TRUE, main = "2000s Sentiment")

radar_chart_00s

song10_nrc <- song_tidy10 %>% 
  inner_join(nrc) %>% 
  filter(!sentiment %in% c("negative", "positive")) %>% 
  group_by(sentiment) %>%
  summarise(Sent_Count = sum(n)) %>% 
  mutate(Sentiment = (Sent_Count/sum(Sent_Count))*100)

radar_chart_10s <- song10_nrc %>%
  select(-Sent_Count) %>% 
  chartJSRadar(showToolTipLabel = TRUE, main = "2010s Sentiment")

radar_chart_10s
```


```{r}
my_colors <- c("#E69F00", "#56B4E9", "#009E73", "#CC79A7", "#D55E00")

theme_lyrics <- function() 
{
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_blank(), 
        axis.ticks = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none")
}

lex_diversity_per_year <- songs %>%
  unnest_tokens(word, Lyrics) %>%
  group_by(Song.Title,Year) %>%
  summarise(lex_diversity = n_distinct(word)) %>%
  arrange(desc(lex_diversity)) 

diversity_plot <- lex_diversity_per_year %>%
  ggplot(aes(Year, lex_diversity)) +
    geom_point(color = my_colors[3],
               alpha = .3, 
               size = 1, position = "jitter") + 
    stat_smooth(color = "black", se = FALSE, method = "lm") +
    geom_smooth(aes(x = Year, y = lex_diversity), se = FALSE,
                color = "blue", lwd = 2) +
    ggtitle("Lexical Diversity") +
    xlab("Year") + 
    ylab("") +
    scale_color_manual(values = my_colors) +
    theme_classic() + 
    theme_lyrics()

diversity_plot
```


```{r}
lex_density_per_year <- songs %>%
  unnest_tokens(word, Lyrics) %>%
  group_by(Song.Title,Year) %>%
  summarise(lex_density = n_distinct(word)/n()) %>%
  arrange(desc(lex_density))

density_plot <- lex_density_per_year %>%
  ggplot(aes(Year, lex_density)) + 
    geom_point(color = my_colors[4],
               alpha = .4, 
               size = 2, 
               position = "jitter") + 
    stat_smooth(color = "black", 
                se = FALSE, 
                method = "lm") +
    geom_smooth(aes(x = Year, y = lex_density), 
                  se = FALSE,
                  color = "blue", 
                  lwd = 2) +
      ggtitle("Lexical Density") + 
      xlab("Year") + 
      ylab("") +
      scale_color_manual(values = my_colors) +
      theme_classic() + 
      theme_lyrics()

density_plot

```


```{r}
library(tidytext) 
library(RColorBrewer)

tfidf_words_decade <- songs %>%
  unnest_tokens(word, Lyrics) %>%
  distinct() %>%
  filter(nchar(word) > 3) %>%
  count(Decade, word, sort = TRUE) %>%
  bind_tf_idf(word, Decade, n) %>%
  arrange(desc(tf_idf))

top_tfidf_words_decade <- tfidf_words_decade %>% 
  group_by(Decade) %>% 
  slice(seq_len(8)) %>%
  ungroup() %>%
  arrange(Decade, tf_idf) %>%
  mutate(row = row_number())

top_tfidf_words_decade %>%
  ggplot(aes(x = row, tf_idf, fill = Decade)) +
    geom_col(show.legend = NULL) +
    labs(x = NULL, y = "TF-IDF") + 
    ggtitle("Important Words using TF-IDF by Decade") +
    theme_lyrics() +  
    facet_wrap(~Decade, 
               ncol = 3, nrow = 2, 
               scales = "free") +
    scale_x_continuous(  # this handles replacement of row 
        breaks = top_tfidf_words_decade$row, # notice need to reuse dataframe
        labels = top_tfidf_words_decade$word) +
    coord_flip()
```

```{r}
timeless_artists <- songs %>%
  select(Artist, Year) %>%
  group_by(Year) %>%
  distinct(Artist) %>%
  ungroup() %>%
  group_by(Artist) %>%
  count() %>%
  arrange(desc(n)) %>%
  head(25)

topartist_token <- songs %>%
  mutate(timeless = ifelse(Artist == "Madonna" | Artist == "Elton John" | Artist == "Mariah Carey" | Artist == "Taylor Swift" | Artist == "Chicago" | Artist == "Stevie Wonder" | Artist == "Kelly Clarkson" | Artist == "Michael Jackson" | Artist == "Rihanna" | Artist == "Aerosmith" | Artist == "Daryl Hall and John Oates" | Artist ==	"Drake"	| Artist == "Janet Jackson" | Artist ==	"Beyonce"	| Artist == "Bon Jovi" | Artist == "Celine Dion" | Artist == "Cher" | Artist == "Commodores" | Artist == "Eminem" | Artist == "Eric Clapton" | Artist == "Justin Timberlake" | Artist == "Maroon 5" | Artist == "Olivia Newton-John" | Artist =="Rod Stewart" | Artist =="Usher", "Top Artist", "Total"))

 

tfidf_words_timeless <- topartist_token %>%
  unnest_tokens(word, Lyrics) %>%
  distinct() %>%
  filter(nchar(word) > 3) %>%
  count(timeless, word, sort = TRUE) %>%
  bind_tf_idf(word, timeless, n) %>%
  arrange(desc(tf_idf))

top_tfidf_words_timeless <- tfidf_words_timeless %>% 
  group_by(timeless) %>% 
  slice(seq_len(10)) %>%
  ungroup() %>%
  arrange(timeless, tf_idf) %>%
  mutate(row = row_number())

top_tfidf_words_timeless %>%
  ggplot(aes(x = row, tf_idf, fill = timeless)) +
    geom_col(show.legend = NULL) +
    labs(x = NULL, y = "TF-IDF") + 
    ggtitle("Important Words using TF-IDF by Decade") +
    theme_lyrics() +  
    facet_wrap(~timeless, 
               ncol = 3, nrow = 2, 
               scales = "free") +
    scale_x_continuous(  # this handles replacement of row 
        breaks = top_tfidf_words_timeless$row, # notice need to reuse dataframe
        labels = top_tfidf_words_timeless$word) +
    coord_flip()

```

```{r}
library(reshape2)
library(wordcloud)


song_compcloud70 <- songtoken70 %>% 
  inner_join(bing) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)


song_tidy80 <- songtoken80 %>% 
  inner_join(bing) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)


song_tidy90 <- songtoken90 %>% 
  inner_join(bing) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)

song_tidy00 <- songtoken00 %>% 
  inner_join(bing) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)

song_tidy10 <- songtoken10 %>% 
  inner_join(bing) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)



```

```{r}
# library(cleanNLP)
# 
# cnlp_init_udpipe()
# 
# annotation <- songs$Corpus %>% cnlp_annotate()
```

```{r}

song_noun <- songs %>% 
  dplyr::select(Song.Title, Nouns, Year) %>% 
  unnest_tokens(output = word, input = Nouns) %>% 
  mutate(Upos = "NOUN") %>% 
  mutate(Year = Year)

song_verb <- songs %>% 
  dplyr::select(Song.Title, Verbs, Year) %>% 
  unnest_tokens(output = word, input = Verbs)%>% 
  mutate(Upos = "VERB") %>% 
  mutate(Year = Year)

song_adverb <- songs %>% 
  dplyr::select(Song.Title, Adverbs, Year) %>% 
  unnest_tokens(output = word, input = Adverbs)%>% 
  mutate(Upos = "ADV") %>% 
  mutate(Year = Year)

song_upos <- rbind(rbind(song_noun,song_verb), song_adverb)
```

```{r}
# annotation_song = annotation$token %>% 
#   rename(id = doc_id, word = token)
# 
# source_tidy <- annotation_song %>%
#   distinct() %>% 
#   select(document = id, word, lemma, upos) %>%
#   filter(upos == "NOUN") %>% #choose only the nouns
#   inner_join(song_noun, by = c("word")) %>%
#   select(document, word, lemma, upos)
# 
# source_dtm <- source_tidy %>%
#   #filter out some words that exist across themes just for our purposes
#   filter(!word %in% c("love", "time", "day", "night", "girl")) %>%
#   count(document, word, sort = TRUE) %>%
#   ungroup() %>%
#   cast_dtm(document, word, n)

# k <- 7
# num_words <- 6
# seed = 4321
# lda <- LDA(source_dtm, k = k, method = "GIBBS",
# 
# control = list(seed = seed))
# 
# top_terms_per_topic(lda, num_words)
```
```{r}
# library(topicmodels)
# data("AssociatedPress", package = "topicmodels")
# AssociatedPress$dimnames$Docs

```
  
